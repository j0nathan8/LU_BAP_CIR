---
title: "Jonathan Homework 1"
output: html_document
date: "2025-02-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries, import the data
library(ggplot2)
library(MASS)
library(devtools)  
attach(Boston)
library(httr)
library(kknn)
library(latex2exp)
library(tm)
library(SnowballC)
library(wordcloud)
library(e1071)
library(caret)
library(pander)
data_cl <- read.csv("https://raw.githubusercontent.com/babakrezaee/MethodsCourses/master/LeidenUniv_MAQM2020/Datasets/R%26P_RezaeeAsadzadeh_MethodsCourse.csv")
```

## 5.2.2. KNN For Violent Methods

The following section will use four features in addition to Violent methods to create a predictive model: Education, Political Knowledge, Income, and Age. 

```{r KNN, echo=FALSE}
X=cbind(data_cl$Violent_method,data_cl$Education_Col,data_cl$Poli_Knowledge,data_cl$Income_ID,data_cl$Age)
mmsc=function(x){return((x-min(x))/(max(x)-min(x)))}
X <- na.omit(X)  # remove rows with NA
X_s=apply(X, 2, mmsc)
set.seed(10)
kv=2:10
ndocv=10
cv_mat_5=matrix(0,length(kv),ndocv)
for (i in 1:ndocv){
  cv_temp=docvknn(X_s,data_cl$Violent_method,kv,nfold=5)
  cv_mat_5[,i]=sqrt(cv_temp/length(data_cl$Violent_method))
}
cv_mean_5=apply(cv_mat_5,1,mean)

kbest_5 = kv[which.min(cv_mean_5)]
cat("The min value of RMSE for 5-fold cross-validation is associated with k=",kbest_5,"\n")
#We now know the optimal k-value is 2. 
#I was unable to make the graph work with all of the variables I chose to use.
```
##5.3 Naives Bayes algorithm

```{r NBA, echo=FALSE}

library(tm)
library(SnowballC)
library(e1071)
library(caret)
library(pander)
library(klaR)
frqtab <- function(x, caption) {
  round(100*prop.table(table(x)), 1)
}

twitterData <- read.csv("https://raw.githubusercontent.com/cardiffnlp/politics-and-virality-twitter/refs/heads/main/data/annotation/en/en_900.csv", 
                    stringsAsFactors = FALSE, encoding="UTF-8")
dim(twitterData)
twitterData <- twitterData[1:999, ]
twitterData$label <- factor(twitterData$label)

twitterCorpus <- VCorpus(VectorSource(twitterData$full_text))

twitterCL <- tm_map(twitterCorpus, content_transformer(tolower)) 
twitterCL <- tm_map(twitterCL, removeNumbers)  
twitterCL <- tm_map(twitterCL, removeWords, stopwords()) 
twitterCL <- tm_map(twitterCL, removePunctuation)
twitterCL <- tm_map(twitterCL, stemDocument) 
twitterCL <- tm_map(twitterCL, stripWhitespace) 
twitterCL <- tm_map(twitterCL, content_transformer(function(x) iconv(x, from = "UTF-8", to = "ASCII", sub="")))


twitterDTM <- DocumentTermMatrix(twitterCL)

set.seed(7)
train_index <- createDataPartition(twitterData$label, p=0.8, list=FALSE)

twitterData_train <- twitterData[train_index,]
twitterData_test <- twitterData[-train_index,]
twitterData_train <- twitterData_train[complete.cases(twitterData_train), ]
twitterCL_train <- twitterCL[train_index]
twitterCL_test <- twitterCL[-train_index]
twitterDTM_train <- twitterDTM[train_index,]
twitterDTM_test <- twitterDTM[-train_index,]

ft_orig <- frqtab(twitterData$label)
ft_train <- frqtab(twitterData_train$label)
ft_test <- frqtab(twitterData_test$label)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
       caption=paste0("Comparison of twitter label frequencies among datasets"))

twitter_dict <- findFreqTerms(twitterDTM_train, lowfreq=10)
twitter_train <- DocumentTermMatrix(twitterCL_train, list(dictionary=twitter_dict))
twitter_test <- DocumentTermMatrix(twitterCL_test, list(dictionary=twitter_dict))

convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("Other", "Positive"))
}

twitter_train = apply(twitter_train, MARGIN = 2, convert_counts)
twitter_test = apply(twitter_test, MARGIN = 2, convert_counts)



train_control <- trainControl(method = "repeatedcv",
                              number = 3,   
                              repeats = 1,   
                              verboseIter = TRUE) 

twitter_train <- twitter_train[1:length(twitterData_train$label), ]

set.seed(7) 
twitterNB_1 <- train(twitter_train, twitterData_train$label, method="nb",
                     trControl=train_control)
#An error appears here that I am unable to resolve, CGPT is completely useless for this error, I have spent over an hour attempting to debug it, I am sure I would be able to do better had I not missed the class.
print(twitterNB_1)

yhat <- predict(twitterNB_1, twitter_test)

ctab <- table(yhat, twitterData_test$label)
print(ctab)

missClass <- 1 - sum(diag(ctab)) / sum(ctab)

perPositive <- ctab["Yes", "Yes"] / sum(ctab[, "Yes"])  

cat("Misclassification rate:", round(missClass, 2) * 100, "%\n")
cat("Positive classification rate:", round(perPositive, 2) * 100, "%\n")


tune_grid <- expand.grid(
  fL = 1, 
  usekernel = FALSE,
  adjust = 1
)

set.seed(7)
twitterNB_2 <- train(twitter_train, twitterData_train$label, method="nb", 
                 tuneGrid=tune_grid,
                 trControl=train_control)
print(twitterNB_2)


yhat <- predict(twitterNB_2, twitter_test)

ctab <- table(yhat, twitterData_test$label)
print(ctab)

missClass <- 1 - sum(diag(ctab)) / sum(ctab)
perPositive <- ctab["Yes", "Yes"] / sum(ctab[, "Yes"])

cat("Misclassification rate:", round(missClass, 2) * 100, "%\n")
cat("Positive classification rate:", round(perPositive, 2) * 100, "%\n")

```

##Feedback
I did not do well on this assignment, I spent a long time trying to debug all the errors my code kept giving me, and had to give up on making a graph for the KNN exercise. I apologise for this unsuccessful assignment and promise to do better in the remaining homework and all other work I will have to produce for this class. 